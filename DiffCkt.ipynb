{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNzlkrkG1PgSuQQ82bh4LqC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cortalo/DiffCkt/blob/master/DiffCkt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nYU5zM95zsA",
        "outputId": "6b2406ad-879a-4f8a-aad8-c36637311e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import zipfile\n",
        "import torch\n",
        "import warnings\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CircuitDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for circuit graph data with fixed-size tensors.\n",
        "\n",
        "    Each sample contains:\n",
        "        - Node features (X)\n",
        "        - Edge features (E)\n",
        "        - Circuit performance (Y)\n",
        "        - Node masks (node_mask)\n",
        "    \"\"\"\n",
        "    def __init__(self, data_list):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_list: List[dict] where each dictionary contains:\n",
        "                - X: [22, 21] node features (float32)\n",
        "                - E: [22, 22, 25] edge features (float32)\n",
        "                - Y: [13] circuit performance (float32)\n",
        "                - node_mask: [22] node masks (bool)\n",
        "        \"\"\"\n",
        "        self.data = data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        return {\n",
        "            'X': torch.from_numpy(sample['X']).float(),  # convert to torch.tensor\n",
        "            'E': torch.from_numpy(sample['E']).float(),\n",
        "            'Y': torch.from_numpy(sample['Y']).float(),\n",
        "            'node_mask': torch.from_numpy(sample['node_mask']).bool()\n",
        "        }\n",
        "\n",
        "\n",
        "def unzip_with_progress(zip_path, target_dir):\n",
        "    \"\"\"Extract ZIP file and print current file being processed.\n",
        "\n",
        "    Args:\n",
        "        zip_path: Path to source ZIP file\n",
        "        target_dir: Destination directory for extracted files\n",
        "\n",
        "    Returns:\n",
        "        bool: True if extraction succeeded, False otherwise\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(target_dir)\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to extract {os.path.basename(zip_path)}: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def unzip_all_data_chunks():\n",
        "    \"\"\"Chunk processing for all data chunk ZIP files in current directory.\"\"\"\n",
        "    print(\"Starting data chunk extraction of data_chunks_*.zip files...\")\n",
        "    pattern = re.compile(r'^data_chunks_\\d+\\.zip$')\n",
        "    current_dir = os.getcwd()\n",
        "    target_dir = os.path.join(current_dir, \"unzipped_data\")\n",
        "\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    print(f\"Extraction directory: {target_dir}\")\n",
        "\n",
        "    zip_files = [f for f in os.listdir(current_dir) if pattern.match(f)]\n",
        "    if not zip_files:\n",
        "        print(\"No data_chunks_*.zip files found\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(zip_files)} files to extract\")\n",
        "\n",
        "    success_count = 0\n",
        "    for i, zip_file in enumerate(zip_files, 1):\n",
        "        print(f\"Processing file {i}/{len(zip_files)}: {zip_file}\")\n",
        "        zip_path = os.path.join(current_dir, zip_file)\n",
        "        if unzip_with_progress(zip_path, target_dir):\n",
        "            success_count += 1\n",
        "\n",
        "    print(f\"\\nExtraction complete: {success_count}/{len(zip_files)} files processed\\n\")\n",
        "\n",
        "def load_data(dir_path='unzipped_data'):\n",
        "    \"\"\"Load and concatenate all circuit data from extracted files.\n",
        "\n",
        "    Args:\n",
        "        dir_path: The directory path of unzipped data, default to 'unzipped_data'\n",
        "    Returns:\n",
        "        CircuitDataset: Initialized dataset object\n",
        "    \"\"\"\n",
        "    # Suppress FutureWarnings\n",
        "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "    files = [f for f in os.listdir(dir_path)]\n",
        "    files = sorted(files, key=lambda x: int(re.search(r'(\\d+)', x).group()))\n",
        "\n",
        "    print(f\"Loading {len(files)} data chunks...\")\n",
        "\n",
        "    data_list = []\n",
        "    for i, file in enumerate(files, 1):\n",
        "        if i % 100 == 1:\n",
        "            print(f\"Loading file {i}/{len(files)}: {file}\")\n",
        "        file_path = os.path.join(dir_path, file)\n",
        "        data_chunk = torch.load(file_path, weights_only=False)\n",
        "        data_list.extend(data_chunk)\n",
        "\n",
        "    circuit_dataset = CircuitDataset(data_list)\n",
        "    print(\"Circuit dataset is created and returned\")\n",
        "    return circuit_dataset\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #unzip_all_data_chunks() # extract data chunk (execute only once)\n",
        "    print(\"finished\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Sh4AeNDDLJp",
        "outputId": "ed2d87c6-2f81-4331-970f-3d7aed90da7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 1143 data chunks...\n",
            "Loading file 1/1143: data_chunk_0.pt\n",
            "Loading file 101/1143: data_chunk_100.pt\n",
            "Loading file 201/1143: data_chunk_200.pt\n",
            "Loading file 301/1143: data_chunk_300.pt\n",
            "Loading file 401/1143: data_chunk_400.pt\n",
            "Loading file 501/1143: data_chunk_500.pt\n",
            "Loading file 601/1143: data_chunk_600.pt\n",
            "Loading file 701/1143: data_chunk_700.pt\n",
            "Loading file 801/1143: data_chunk_800.pt\n",
            "Loading file 901/1143: data_chunk_900.pt\n",
            "Loading file 1001/1143: data_chunk_1000.pt\n",
            "Loading file 1101/1143: data_chunk_1100.pt\n",
            "Circuit dataset is created and returned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.__getitem__(0)\n",
        "print(\"hello\")"
      ],
      "metadata": {
        "id": "V7TmiWqnFLU0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}